{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.smith.langchain.com/evaluation/tutorials/evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate a chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['93847b75-9645-42c9-ba7d-904688d7bab3',\n",
       "  '5b5d2e2a-e1ed-4472-9297-43b211993077',\n",
       "  '294389ea-b75e-4348-b1a9-c0e3057fd0bc',\n",
       "  '8276b532-d357-40f4-b80a-314c056a2f6c',\n",
       "  'ff235f8a-85da-4569-82b8-ae622fbe4de4'],\n",
       " 'count': 5}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# Define dataset: these are your test cases\n",
    "dataset_name = \"QA Example Dataset\"\n",
    "dataset = client.create_dataset(dataset_name)\n",
    "client.create_examples(\n",
    "    dataset_id=dataset.id,\n",
    "    examples=[\n",
    "        {\n",
    "            \"inputs\": {\"question\": \"What is LangChain?\"},\n",
    "            \"outputs\": {\"answer\": \"A framework for building LLM applications\"},\n",
    "        },\n",
    "        {\n",
    "            \"inputs\": {\"question\": \"What is LangSmith?\"},\n",
    "            \"outputs\": {\"answer\": \"A platform for observing and evaluating LLM applications\"},\n",
    "        },\n",
    "        {\n",
    "            \"inputs\": {\"question\": \"What is OpenAI?\"},\n",
    "            \"outputs\": {\"answer\": \"A company that creates Large Language Models\"},\n",
    "        },\n",
    "        {\n",
    "            \"inputs\": {\"question\": \"What is Google?\"},\n",
    "            \"outputs\": {\"answer\": \"A technology company known for search\"},\n",
    "        },\n",
    "        {\n",
    "            \"inputs\": {\"question\": \"What is Mistral?\"},\n",
    "            \"outputs\": {\"answer\": \"A company that creates Large Language Models\"},\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langsmith import wrappers\n",
    "\n",
    "openai_client = wrappers.wrap_openai(openai.OpenAI())\n",
    "\n",
    "eval_instructions = \"You are an expert professor specialized in grading students' answers to questions.\"\n",
    "\n",
    "def correctness(inputs: dict, outputs: dict, reference_outputs: dict) -> bool:\n",
    "    user_content = f\"\"\"You are grading the following question:\n",
    "                {inputs['question']}\n",
    "                Here is the real answer:\n",
    "                {reference_outputs['answer']}\n",
    "                You are grading the following predicted answer:\n",
    "                {outputs['response']}\n",
    "                Respond with CORRECT or INCORRECT:\n",
    "                Grade:\n",
    "                \"\"\"\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": eval_instructions},\n",
    "            {\"role\": \"user\", \"content\": user_content},\n",
    "        ],\n",
    "    ).choices[0].message.content\n",
    "    return response == \"CORRECT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concision(outputs: dict, reference_outputs: dict) -> bool:\n",
    "    return int(len(outputs[\"response\"]) < 2 * len(reference_outputs[\"answer\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_instructions = \"Respond to the users question in a short, concise manner (one short sentence).\"\n",
    "\n",
    "def my_app(question: str, model: str = \"gpt-4o-mini\", instructions: str = default_instructions) -> str:\n",
    "    return openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": instructions},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ],\n",
    "    ).choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_target(inputs: str) -> dict:\n",
    "    return {\"response\": my_app(inputs[\"question\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'openai-4o-mini-e72c1e05' at:\n",
      "https://smith.langchain.com/o/cb610865-43f4-4b0e-98d4-572b2702d7c7/datasets/53c78873-415e-4223-bb88-9c41ce2c4d00/compare?selectedSessions=b969e863-068b-44ad-8b43-8557790ec927\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090ce7679fb64f3db97a74b39872fb88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment_results = client.evaluate(\n",
    "    ls_target, # Your AI system\n",
    "    data=dataset_name, # The data to predict and grade over\n",
    "    evaluators=[concision, correctness], # The evaluators to score the results\n",
    "    experiment_prefix=\"openai-4o-mini\", # A prefix for your experiment names to easily identify them\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'openai-4-turbo-e201ad13' at:\n",
      "https://smith.langchain.com/o/cb610865-43f4-4b0e-98d4-572b2702d7c7/datasets/53c78873-415e-4223-bb88-9c41ce2c4d00/compare?selectedSessions=50aaef30-5064-4332-83b9-9d4447ff8c13\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61862cefa63c4e1493d7a80ada215a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "    ~~^\n",
      "        *args,\n",
      "        ^^^^^^\n",
      "        langsmith_extra=langsmith_extra,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/1529853405.py\", line 2, in ls_target_v2\n",
      "    return {\"response\": my_app(inputs[\"question\"], model=\"gpt-4-turbo\")}\n",
      "                        ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_222072/1008731419.py\", line 4, in my_app\n",
      "    return openai_client.chat.completions.create(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        model=model,\n",
      "        ^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    ).choices[0].message.content\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/wrappers/_openai.py\", line 270, in create\n",
      "    return decorator(original_create)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<41 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        cast_to=cast_to,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        retries_taken=retries_taken,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.PermissionDeniedError: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Error running evaluator <DynamicRunEvaluator concision> on run 640bc809-84b1-4952-948b-d351513b0942: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/3077211258.py\", line 2, in concision\n",
      "    return int(len(outputs[\"response\"]) < 2 * len(reference_outputs[\"answer\"]))\n",
      "                   ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 640bc809-84b1-4952-948b-d351513b0942: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/2811389316.py\", line 14, in correctness\n",
      "    {outputs['response']}\n",
      "     ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "    ~~^\n",
      "        *args,\n",
      "        ^^^^^^\n",
      "        langsmith_extra=langsmith_extra,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/1529853405.py\", line 2, in ls_target_v2\n",
      "    return {\"response\": my_app(inputs[\"question\"], model=\"gpt-4-turbo\")}\n",
      "                        ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_222072/1008731419.py\", line 4, in my_app\n",
      "    return openai_client.chat.completions.create(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        model=model,\n",
      "        ^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    ).choices[0].message.content\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/wrappers/_openai.py\", line 270, in create\n",
      "    return decorator(original_create)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<41 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        cast_to=cast_to,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        retries_taken=retries_taken,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.PermissionDeniedError: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Error running evaluator <DynamicRunEvaluator concision> on run 0f9bb6aa-e8d0-4c89-b942-afcd65e68a36: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/3077211258.py\", line 2, in concision\n",
      "    return int(len(outputs[\"response\"]) < 2 * len(reference_outputs[\"answer\"]))\n",
      "                   ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 0f9bb6aa-e8d0-4c89-b942-afcd65e68a36: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/2811389316.py\", line 14, in correctness\n",
      "    {outputs['response']}\n",
      "     ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "    ~~^\n",
      "        *args,\n",
      "        ^^^^^^\n",
      "        langsmith_extra=langsmith_extra,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/1529853405.py\", line 2, in ls_target_v2\n",
      "    return {\"response\": my_app(inputs[\"question\"], model=\"gpt-4-turbo\")}\n",
      "                        ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_222072/1008731419.py\", line 4, in my_app\n",
      "    return openai_client.chat.completions.create(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        model=model,\n",
      "        ^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    ).choices[0].message.content\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/wrappers/_openai.py\", line 270, in create\n",
      "    return decorator(original_create)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<41 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        cast_to=cast_to,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        retries_taken=retries_taken,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.PermissionDeniedError: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Error running evaluator <DynamicRunEvaluator concision> on run e5df028d-8e91-47f4-bf8e-0e6f14175f47: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/3077211258.py\", line 2, in concision\n",
      "    return int(len(outputs[\"response\"]) < 2 * len(reference_outputs[\"answer\"]))\n",
      "                   ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run e5df028d-8e91-47f4-bf8e-0e6f14175f47: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/2811389316.py\", line 14, in correctness\n",
      "    {outputs['response']}\n",
      "     ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "    ~~^\n",
      "        *args,\n",
      "        ^^^^^^\n",
      "        langsmith_extra=langsmith_extra,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/1529853405.py\", line 2, in ls_target_v2\n",
      "    return {\"response\": my_app(inputs[\"question\"], model=\"gpt-4-turbo\")}\n",
      "                        ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_222072/1008731419.py\", line 4, in my_app\n",
      "    return openai_client.chat.completions.create(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        model=model,\n",
      "        ^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    ).choices[0].message.content\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/wrappers/_openai.py\", line 270, in create\n",
      "    return decorator(original_create)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<41 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        cast_to=cast_to,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        retries_taken=retries_taken,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.PermissionDeniedError: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Error running evaluator <DynamicRunEvaluator concision> on run f41a0776-fb03-4ba4-93b2-99417d174e8b: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/3077211258.py\", line 2, in concision\n",
      "    return int(len(outputs[\"response\"]) < 2 * len(reference_outputs[\"answer\"]))\n",
      "                   ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run f41a0776-fb03-4ba4-93b2-99417d174e8b: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/2811389316.py\", line 14, in correctness\n",
      "    {outputs['response']}\n",
      "     ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "    ~~^\n",
      "        *args,\n",
      "        ^^^^^^\n",
      "        langsmith_extra=langsmith_extra,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/1529853405.py\", line 2, in ls_target_v2\n",
      "    return {\"response\": my_app(inputs[\"question\"], model=\"gpt-4-turbo\")}\n",
      "                        ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_222072/1008731419.py\", line 4, in my_app\n",
      "    return openai_client.chat.completions.create(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        model=model,\n",
      "        ^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    ).choices[0].message.content\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/wrappers/_openai.py\", line 270, in create\n",
      "    return decorator(original_create)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<41 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        cast_to=cast_to,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        retries_taken=retries_taken,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.PermissionDeniedError: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Error running evaluator <DynamicRunEvaluator concision> on run b15f0faf-36c5-4305-9051-f3c4c0f09be0: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/3077211258.py\", line 2, in concision\n",
      "    return int(len(outputs[\"response\"]) < 2 * len(reference_outputs[\"answer\"]))\n",
      "                   ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run b15f0faf-36c5-4305-9051-f3c4c0f09be0: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/2811389316.py\", line 14, in correctness\n",
      "    {outputs['response']}\n",
      "     ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n"
     ]
    }
   ],
   "source": [
    "def ls_target_v2(inputs: str) -> dict:\n",
    "    return {\"response\": my_app(inputs[\"question\"], model=\"gpt-4-turbo\")}\n",
    "\n",
    "experiment_results = client.evaluate(\n",
    "    ls_target_v2,\n",
    "    data=dataset_name,\n",
    "    evaluators=[concision, correctness],\n",
    "    experiment_prefix=\"openai-4-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'strict-openai-4-turbo-bf74528f' at:\n",
      "https://smith.langchain.com/o/cb610865-43f4-4b0e-98d4-572b2702d7c7/datasets/53c78873-415e-4223-bb88-9c41ce2c4d00/compare?selectedSessions=8adabec8-df54-4b2e-94c9-df55d284812d\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41d0c9371ab48e4a20fcf77b3a78bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "    ~~^\n",
      "        *args,\n",
      "        ^^^^^^\n",
      "        langsmith_extra=langsmith_extra,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/1433557006.py\", line 4, in ls_target_v3\n",
      "    response = my_app(\n",
      "        inputs[\"question\"],\n",
      "        model=\"gpt-4-turbo\",\n",
      "        instructions=instructions_v3\n",
      "    )\n",
      "  File \"/tmp/ipykernel_222072/1008731419.py\", line 4, in my_app\n",
      "    return openai_client.chat.completions.create(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        model=model,\n",
      "        ^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    ).choices[0].message.content\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/wrappers/_openai.py\", line 270, in create\n",
      "    return decorator(original_create)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<41 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        cast_to=cast_to,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        retries_taken=retries_taken,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.PermissionDeniedError: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Error running evaluator <DynamicRunEvaluator concision> on run 8555ff33-433f-48c2-91c3-121a1714994d: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/3077211258.py\", line 2, in concision\n",
      "    return int(len(outputs[\"response\"]) < 2 * len(reference_outputs[\"answer\"]))\n",
      "                   ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 8555ff33-433f-48c2-91c3-121a1714994d: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/2811389316.py\", line 14, in correctness\n",
      "    {outputs['response']}\n",
      "     ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "    ~~^\n",
      "        *args,\n",
      "        ^^^^^^\n",
      "        langsmith_extra=langsmith_extra,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/1433557006.py\", line 4, in ls_target_v3\n",
      "    response = my_app(\n",
      "        inputs[\"question\"],\n",
      "        model=\"gpt-4-turbo\",\n",
      "        instructions=instructions_v3\n",
      "    )\n",
      "  File \"/tmp/ipykernel_222072/1008731419.py\", line 4, in my_app\n",
      "    return openai_client.chat.completions.create(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        model=model,\n",
      "        ^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    ).choices[0].message.content\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/wrappers/_openai.py\", line 270, in create\n",
      "    return decorator(original_create)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<41 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        cast_to=cast_to,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        retries_taken=retries_taken,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.PermissionDeniedError: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Error running evaluator <DynamicRunEvaluator concision> on run 400abbaa-f878-4985-a5dc-360b7c3b3247: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/3077211258.py\", line 2, in concision\n",
      "    return int(len(outputs[\"response\"]) < 2 * len(reference_outputs[\"answer\"]))\n",
      "                   ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 400abbaa-f878-4985-a5dc-360b7c3b3247: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/2811389316.py\", line 14, in correctness\n",
      "    {outputs['response']}\n",
      "     ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "    ~~^\n",
      "        *args,\n",
      "        ^^^^^^\n",
      "        langsmith_extra=langsmith_extra,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/1433557006.py\", line 4, in ls_target_v3\n",
      "    response = my_app(\n",
      "        inputs[\"question\"],\n",
      "        model=\"gpt-4-turbo\",\n",
      "        instructions=instructions_v3\n",
      "    )\n",
      "  File \"/tmp/ipykernel_222072/1008731419.py\", line 4, in my_app\n",
      "    return openai_client.chat.completions.create(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        model=model,\n",
      "        ^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    ).choices[0].message.content\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/wrappers/_openai.py\", line 270, in create\n",
      "    return decorator(original_create)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<41 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        cast_to=cast_to,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        retries_taken=retries_taken,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.PermissionDeniedError: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Error running evaluator <DynamicRunEvaluator concision> on run 8b673281-e9e5-4a35-a359-63f06c205c36: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/3077211258.py\", line 2, in concision\n",
      "    return int(len(outputs[\"response\"]) < 2 * len(reference_outputs[\"answer\"]))\n",
      "                   ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 8b673281-e9e5-4a35-a359-63f06c205c36: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/2811389316.py\", line 14, in correctness\n",
      "    {outputs['response']}\n",
      "     ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "    ~~^\n",
      "        *args,\n",
      "        ^^^^^^\n",
      "        langsmith_extra=langsmith_extra,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/1433557006.py\", line 4, in ls_target_v3\n",
      "    response = my_app(\n",
      "        inputs[\"question\"],\n",
      "        model=\"gpt-4-turbo\",\n",
      "        instructions=instructions_v3\n",
      "    )\n",
      "  File \"/tmp/ipykernel_222072/1008731419.py\", line 4, in my_app\n",
      "    return openai_client.chat.completions.create(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        model=model,\n",
      "        ^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    ).choices[0].message.content\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/wrappers/_openai.py\", line 270, in create\n",
      "    return decorator(original_create)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<41 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        cast_to=cast_to,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        retries_taken=retries_taken,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.PermissionDeniedError: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Error running evaluator <DynamicRunEvaluator concision> on run 07799fa4-3e64-457d-a096-adee000a60b7: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/3077211258.py\", line 2, in concision\n",
      "    return int(len(outputs[\"response\"]) < 2 * len(reference_outputs[\"answer\"]))\n",
      "                   ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 07799fa4-3e64-457d-a096-adee000a60b7: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/2811389316.py\", line 14, in correctness\n",
      "    {outputs['response']}\n",
      "     ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "    ~~^\n",
      "        *args,\n",
      "        ^^^^^^\n",
      "        langsmith_extra=langsmith_extra,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/1433557006.py\", line 4, in ls_target_v3\n",
      "    response = my_app(\n",
      "        inputs[\"question\"],\n",
      "        model=\"gpt-4-turbo\",\n",
      "        instructions=instructions_v3\n",
      "    )\n",
      "  File \"/tmp/ipykernel_222072/1008731419.py\", line 4, in my_app\n",
      "    return openai_client.chat.completions.create(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        model=model,\n",
      "        ^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    ).choices[0].message.content\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/wrappers/_openai.py\", line 270, in create\n",
      "    return decorator(original_create)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<41 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        cast_to=cast_to,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        retries_taken=retries_taken,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.PermissionDeniedError: Error code: 403 - {'error': {'message': 'Project `proj_WGWSvViJeuMybNZuPlpT6up4` does not have access to model `gpt-4-turbo`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Error running evaluator <DynamicRunEvaluator concision> on run 392684d0-0ffc-4e06-bdbe-c0cae8a18a07: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/3077211258.py\", line 2, in concision\n",
      "    return int(len(outputs[\"response\"]) < 2 * len(reference_outputs[\"answer\"]))\n",
      "                   ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 392684d0-0ffc-4e06-bdbe-c0cae8a18a07: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/home/keny/Programs/Python/RAG/langsmitsh_tutorial/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_222072/2811389316.py\", line 14, in correctness\n",
      "    {outputs['response']}\n",
      "     ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n"
     ]
    }
   ],
   "source": [
    "instructions_v3 = \"Respond to the users question in a short, concise manner (one short sentence). Do NOT use more than ten words.\"\n",
    "\n",
    "def ls_target_v3(inputs: str) -> dict:\n",
    "    response = my_app(\n",
    "        inputs[\"question\"], \n",
    "        model=\"gpt-4-turbo\",\n",
    "        instructions=instructions_v3\n",
    "    )\n",
    "    return {\"response\": response}\n",
    "\n",
    "\n",
    "experiment_results = client.evaluate(\n",
    "    ls_target_v3,\n",
    "    data=dataset_name,\n",
    "    evaluators=[concision, correctness],\n",
    "    experiment_prefix=\"strict-openai-4-turbo\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
